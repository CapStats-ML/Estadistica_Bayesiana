El enunciado del 4to punto a desarrollar dice lo siguiente:  Para Bogotá en todos los periodos ($t=1,\ldots,9$), calcule la media posterior y el intervalo de credibilidad al 95$\%$ de confianza para el coeficiente de variación $\zeta$. Presente los resultados mediante una visualización que muestre simultáneamente las medias posteriores y los intervalos de credibilidad.

Con esto los paso a seguir son los siguientes:

   - Repetir el análisis anterior, pero enfocado en el coeficiente de variación.
   - Presentar los resultados de manera gráfica.

```{r}
resultados <- list()

for (i in 1:length(bases)) {
  dat <- bases[[i]]
  dat <- as.data.frame(dat)
  
  resultados[[i]] <- bayesian_analysis(dat, depto_res_col = "ESTU_COD_RESIDE_DEPTO", 
                                  depto_code = 11, score_col = "PUNT_MATEMATICAS",
                                  save_samples = FALSE)
}

tablas <- lapply(resultados, function(x) x$resultados)
```


Luego de ajustar los modelos con respecto a esos diferentes periodos, la tabla para la visualización de estos resultados estaría dada de la siguiente manera


```{r}
tablas_procesadas <- lapply(tablas, procesar_kable)

# Extraer los datos necesarios
años <- 2015:2023

Cvar <- numeric(length(tablas_procesadas))
for (i in 1:length(tablas_procesadas)) {
  Cvar[i] <- as.numeric(tablas_procesadas[[i]]$` Estimación `[3])
}

cv <- numeric(length(tablas_procesadas))
for (i in 1:length(tablas_procesadas)) {
  cv[i] <- as.numeric(tablas_procesadas[[i]]$`  CV   `[3])
}

ic_inf <- numeric(length(tablas_procesadas))
for (i in 1:length(tablas_procesadas)) {
  ic_inf[i] <- as.numeric(tablas_procesadas[[i]]$` L. Inf. `[3])
}

ic_sup <- numeric(length(tablas_procesadas))
for (i in 1:length(tablas_procesadas)) {
  ic_sup[i] <- as.numeric(tablas_procesadas[[i]]$` L. Sup. `[3])
}


# Verificar los datos
X <- data.frame(Theta = Cvar, CV = cv, IC_Inf = ic_inf, IC_Sup = ic_sup)

colnames(X) <- c("Estimación", "Coef Var" , "Q2.5%","Q97.5%")
rownames(X) <- c(2015:2023)


knitr::kable(X, digits = 3, align = "c", 
             caption = "Inferencia Bayesiana en todos los periodos para Bogotá")
```

De la tabla se puede decir que a modo general durante los periodos estudiados los intervalos de credibilidad tienden a "atrapar" ese valor promedio estándar de 0.2 que se tiene como referencia a nivel poblacional para la prueba, lo cual indica que no hay evidencia estadística que sugiera que dicho valor es diferente a este 0.2 de referencia, sin embargo, para los periodos de 2015 y 2023 se ve que los límites están significativamente por encima de dicho valor, así entonces se concluye que con una probabilidad del $95\%$ el coeficiente de variación para la prueba en estos periodos es mayor que el valor de 0.2 esperado, esto indica que habría una mayor volatilidad en los resultados, lo cual se traduce en poder ver tanto puntajes muy bajos como muy altos para ciertos individuos.

Nuevamente, de manera extra se adjunta un nuevo gráfico de las estimaciones junto con sus correspondientes intervalos pero en este caso para el coeficiente de variación. 


```{r}
# Definir colores en función del valor de Theta (personalizable)
colores <- rep("black", length(Cvar))
colores[Cvar < 0.19] <- "royalblue" # Ejemplo: rojo si Theta < 50
colores[Cvar > 0.21] <- "red"

par(mfrow = c(1, 1), mar = c(5, 5, 4, 4), bg = "white")

# Configurar el gráfico
plot(
  NA, NA, 
  xlab = expression(paste("ESTIMACIÓN DE ", zeta)), 
  ylab = "AÑO", 
  xlim = range(c(ic_inf, ic_sup)), 
  ylim = c(2015, 2023), 
  main = "ESTIMACIÓN COEF de VAR DEL PUNTAJE EN MATEMÁTICAS EN BOGOTÁ", 
  yaxt = "n", cex.axis = 0.7, cex.lab = 0.8, 
  font.lab = 2, font.main = 2, cex.main = 1, 
  col.axis = "grey20", col.main = "black", 
  font = 2, fg = alpha('grey20', 1), family = "sans"
)

# Eje Y con los años
axis(side = 2, at = años, labels = años, las = 2, cex.axis = 0.7, col = "grey20")

# Líneas de referencia
abline(v = 0.2, col = "gray", lwd = 2)
abline(h = años, col = "lightgray", lwd = 1)

# Dibujar los intervalos de confianza y los puntos
for (i in seq_along(años)) {
  segments(x0 = ic_inf[i], y0 = años[i], x1 = ic_sup[i], y1 = años[i], col = colores[i])
  points(Cvar[i], años[i], pch = 16, cex = 0.8, col = colores[i])
}

# Agregar título al gráfico
mtext("SIMULACIÓN MONTE CARLO DE LOS VALORES DE Cvar POR AÑOS", side = 3, line = 0.5, cex = 0.8, col = "grey20", font = 2)

# Leyenda
legend("topright", legend = c("CV ALTO", "CV MEDIO", "CV BAJO", "IC 95%"), col = c("red", "royalblue", "black", "gray"), lty = c(1, 2, 2, 1), lwd = 1.2, cex = 0.8)

```


Del gráfico, se ve que al tomar como referencia la línea estándar del valor de 0.2, la mayoría de los periodos en efecto tienden a comportarse como se esperaría, no obstante, es curioso ver como para los años 2015 y 2023 se obtuvieron coeficientes que sobrepasan lo establecido, tal y como se había mencionado al solo ver la tabla, y aun mejor, para el año 2020 se ve que se tuvieron resultados por debajo de esta referencia, lo cual de cierta manera es "extraño" comparando con los demás periodos, pero a la vez si se le trata de dar un sentido que vaya más allá no resulta tan sospechoso al ser el año en el que se presentó el estallido de la pandemia de COVID 19, con esta información se puede complementar lo ya dicho en el punto anterior sobre la estimación de la media y en realidad se ve que este suceso cobra más fuerza como algo que afectó realmente los puntajes de los exámenes y ¿por qué no?, en general la educación colombiana y su medición tal y como se conocía antes de este suceso, de nuevo, cosas que se dejan en el aire gracias a la información que esconden los datos para que cada uno deje volar su imaginación.

Ahora, observemos en el mapa como se comporta el coeficiente de variación de los puntajes de matemáticas en Bogotá en los diferentes periodos con otro gráfico adicional.


```{r}
# Datos de Theta y años
theta <- c(0.224, 0.196, 0.207, 0.202, 0.206, 0.180, 0.208, 0.210, 0.218)
years <- 2015:2023
theta_df <- data.frame(year = years, Theta = theta)

bogota_shp <- shp[shp$dpto_ccdgo == 11, ]

# Replicar la geometría y asignar Theta
bogota_shp_rep <- bogota_shp %>%
  slice(rep(1, length(years))) %>% # Replicar la fila tantas veces como años
  mutate(year = years) %>%         # Asignar los años correspondientes
  left_join(theta_df, by = "year") # Incorporar el valor de Theta

# Crear la escala global para Theta
min_theta <- min(theta)
max_theta <- max(theta)
```


```{r}
# Generar un mapa para extraer la leyenda global
legend_map <- create_map(bogota_shp_rep %>%
                           filter(year == 2015), 2015, name = "CV")
legend <- cowplot::get_legend(legend_map)

# Generar una lista de mapas sin leyendas
maps <- lapply(years, function(year) {
  year_data <- bogota_shp_rep %>% filter(year == !!year)
  create_map(year_data, year, subtitulo = "CV EN MATEMÁTICAS PARA BOGOTÁ") +
    theme(legend.position = "none")
})

# Combinar todos los mapas en una cuadrícula
combined_maps <- plot_grid(plotlist = maps, ncol = 3)

# Agregar la leyenda global al lado de los mapas
final_plot <- plot_grid(combined_maps, legend, ncol = 2, rel_widths = c(10, 1))

# Mostrar el resultado
print(final_plot)

```

En esta nueva visualización, respectivamente de colores oscuros a claros, se observa como la variación de los puntajes va cambiando de más volátil a menos volátil conforme transcurren los periodos estudiados.